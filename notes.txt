// Α α Alpha a
// Β β Beta b
// Γ γ Gamma g
// Δ δ Delta d
// Ε ε Epsilon e
// Ζ ζ Zeta z
// Η η Eta h
// Θ θ Theta th
// Ι ι Iota i
// Κ κ Kappa k
// Λ λ Lambda l
// Μ μ Mu m
// Ν ν Nu n
// Ξ ξ Xi x
// Ο ο Omicron o
// Π π Pi p
// Ρ ρ Rho r
// Σ σ,ς * Sigma s
// Τ τ Tau t
// Υ υ Upsilon u
// Φ φ Phi ph
// Χ χ Chi ch
// Ψ ψ Psi ps
// Ω ω Omega o



//_w = new double[3][][];

		// _w[0] = new double[2][2];
		// _w[1] = new double[2][3];
		// _w[2] = new double[2][3];
		//
		// _w[1][0][0] = .35;
		// _w[1][0][1] = .15;
		// _w[1][0][2] = .20;
		//
		// _w[1][1][0] = .35;
		// _w[1][1][1] = .25;
		// _w[1][1][2] = .30;
		//
		// _w[2][0][0] = .60;
		// _w[2][0][1] = .40;
		// _w[2][0][2] = .45;
		//
		// _w[2][1][0] = .60;
		// _w[2][1][1] = .50;
		// _w[2][1][2] = .55;




//private void debugNetValues(double[][][] W) {
//	W[1] = new double[3][3];
//	W[1][0] = new double[] { 0.2, 0.4, 0.5 };
//	W[1][1] = new double[] { 0.3, 0.6, 0.7 };
//	W[1][2] = new double[] { 0.4, 0.8, 0.3 };
//
//	W[2] = new double[2][4];
//	W[2][0] = new double[] { -0.7, 0.6, 0.2, 0.7 };
//	W[2][1] = new double[] { -0.3, 0.7, 0.2, 0.8 };
//
//	W[3] = new double[1][3];
//	W[3][0] = new double[] { 0.1, 0.8, 0.5 };

	// Instance[] ex = new Instance[1];
	// ex[0] = new Instance();
	//
	// ex[0].features = new double[] { 0.3, 0.7 };
	// ex[0].target = new double[] { 0.9 };

	// Instance[] ex = new Instance[4];
	//
	// ex[0] = new Instance();
	// ex[0].features = new double[] { 0.2, 0.9, 0.4 };
	// ex[0].target = new double[] { 0.7, 0.3 };
	//
	// ex[1] = new Instance();
	// ex[1].features = new double[] { 0.1, 0.3, 0.5 };
	// ex[1].target = new double[] { 0.6, 0.4 };
	//
	// ex[2] = new Instance();
	// ex[2].features = new double[] { 0.9, 0.7, 0.8 };
	// ex[2].target = new double[] { 0.9, 0.5 };
	//
	// ex[3] = new Instance();
	// ex[3].features = new double[] { 0.6, 0.4, 0.3 };
	// ex[3].target = new double[] { 0.2, 0.8 };
//}




1, 0.6022864019253911, 2.886
2, 0.5788206979542719, 4.129
3, 0.5785198555956679, 1.982
5, 0.6067990373044525, 4.448
10, 0.6254512635379061, 6.941
20, 0.631768953068592, 24.296
30, 0.6308664259927798, 42.712
40, 0.6266546329723225, 54.096
50, 0.6200361010830325, 61.183
60, 0.621841155234657, 84.695
70, 0.6233453670276775, 84.913
80, 0.615222623345367, 114.632
90, 0.6278580024067388, 114.261
100, 0.6134175691937425, 121.498
110, 0.634777376654633, 154.535
120, 0.605294825511432, 108.816
130, 0.635078219013237, 183.781
140, 0.6194344163658243, 197.072
150, 0.635078219013237, 148.565
160, 0.6227436823104693, 224.726
170, 0.6368832731648616, 236.761
180, 0.6471119133574007, 234.776
190, 0.6308664259927798, 225.405
200, 0.6392900120336944, 249.58
210, 0.6329723225030084, 285.266
220, 0.6392900120336944, 310.654
230, 0.6380866425992779, 280.063
240, 0.6335740072202166, 341.031
250, 0.6456077015643803, 291.112
300, 0.6389891696750902, 288.992
400, 0.6398916967509025, 294.952
500, 0.6410950661853189, 609.05
600, 0.6353790613718412, 578.524
700, 0.5785198555956679, 39.891
800, 0.5785198555956679, 45.72
900, 0.338748495788207, 51.483
1000, 0.5785198555956679, 57.044


1, 0.5908543922984356, 3.141, 50
2, 0.5917569193742479, 4.454, 50
3, 0.5785198555956679, 0.819, 6
5, 0.5827316486161251, 4.188, 23
10, 0.6067990373044525, 6.46, 19
20, 0.6113116726835138, 20.63, 32
30, 0.6293622141997594, 28.348, 29
40, 0.6323706377858003, 52.415, 40
50, 0.6323706377858003, 35.907, 22
60, 0.6389891696750902, 82.215, 43
70, 0.6308664259927798, 54.415, 24
80, 0.6308664259927798, 103.898, 40
90, 0.6227436823104693, 113.749, 40
100, 0.6368832731648616, 71.048, 22
110, 0.6425992779783394, 168.584, 48
120, 0.6272563176895307, 163.622, 42
130, 0.6356799037304453, 167.492, 39
140, 0.641395908543923, 145.903, 32
150, 0.6212394705174489, 155.086, 32
160, 0.6441034897713598, 152.089, 29
170, 0.6465102286401926, 279.989, 49
180, 0.6233453670276775, 276.261, 46
190, 0.6371841155234657, 312.899, 50
200, 0.6329723225030084, 119.813, 18
210, 0.6410950661853189, 283.596, 41
220, 0.6410950661853189, 315.409, 44
230, 0.6383874849578821, 184.472, 25
240, 0.6380866425992779, 230.597, 30
250, 0.6236462093862816, 146.323, 18
300, 0.6287605294825511, 194.89, 20
400, 0.6070998796630566, 134.362, 10
500, 0.6371841155234657, 581.65, 36
600, 0.634777376654633, 535.869, 28
700, 0.5785198555956679, 43.006, 1
800, 0.5785198555956679, 49.191, 1
900, 0.5785198555956679, 55.965, 1
1000, 0.5785198555956679, 61.867, 1


net.train(train, 0.5, 50, 0.05, 0.25);

1, 0.6013838748495788, 0.456, 3
2, 0.26504211793020455, 0.318, 2
3, 0.621841155234657, 0.45, 2
5, 0.5932611311672683, 0.9, 3
10, 0.6212394705174489, 1.926, 4
20, 0.618231046931408, 1.802, 2
30, 0.6296630565583634, 2.586, 2
40, 0.6203369434416366, 5.092, 3
50, 0.631768953068592, 4.263, 2
60, 0.6242478941034898, 5.067, 2
70, 0.6335740072202166, 11.777, 4
80, 0.6432009626955475, 6.767, 2
90, 0.6371841155234657, 11.927, 3
100, 0.6335740072202166, 13.479, 3
110, 0.6215403128760529, 9.791, 2
120, 0.6305655836341757, 11.022, 2
130, 0.631468110709988, 11.219, 2
140, 0.6344765342960289, 11.897, 2
150, 0.6173285198555957, 12.861, 2
160, 0.6296630565583634, 14.114, 2
170, 0.6227436823104693, 21.832, 3
180, 0.6293622141997594, 23.453, 3
190, 0.6305655836341757, 16.376, 2
200, 0.6435018050541517, 17.308, 2
210, 0.6299638989169675, 35.906, 4
220, 0.6248495788206979, 18.971, 2
230, 0.6031889290012034, 20.319, 2
240, 0.5914560770156438, 20.052, 2
250, 0.6191335740072202, 21.814, 2
300, 0.5884476534296029, 26.981, 2
400, 0.6359807460890493, 34.552, 2
500, 0.6425992779783394, 42.674, 2
600, 0.6266546329723225, 51.568, 2
700, 0.6245487364620939, 62.664, 2
800, 0.6209386281588448, 72.355, 2
900, 0.6080024067388689, 89.392, 2
1000, 0.6341756919374247, 146.821, 3

net.train(train, 0.5, 50, 0.005, 0.5);
1, 0.5785198555956679, 1.09, 8
2, 0.5694945848375451, 1.058, 6
3, 0.6043922984356197, 0.519, 3
5, 0.5908543922984356, 0.552, 2
10, 0.6098074608904934, 0.93, 2
20, 0.5989771359807461, 4.295, 5
30, 0.6170276774969916, 2.572, 2
40, 0.5505415162454874, 3.476, 2
50, 0.598676293622142, 4.24, 2
60, 0.6061973525872443, 7.419, 3
70, 0.5950661853188929, 8.662, 3
80, 0.6155234657039711, 19.751, 6
90, 0.6239470517448856, 18.695, 5
100, 0.6049939831528279, 20.837, 5
110, 0.6194344163658243, 18.437, 4
120, 0.6064981949458483, 15.156, 3
130, 0.6083032490974729, 10.906, 2
140, 0.5788206979542719, 35.331, 6
150, 0.6296630565583634, 12.693, 2
160, 0.6170276774969916, 26.78, 4
170, 0.6170276774969916, 28.642, 4
180, 0.5848375451263538, 52.844, 7
190, 0.6131167268351384, 39.48, 5
200, 0.6025872442839952, 25.56, 3
210, 0.6257521058965102, 19.62, 2
220, 0.6119133574007221, 18.668, 2
230, 0.6022864019253911, 48.223, 5
240, 0.5953670276774969, 50.651, 5
250, 0.5911552346570397, 21.116, 2
300, 0.589049338146811, 63.223, 5
400, 0.6031889290012034, 66.534, 4
500, 0.5956678700361011, 41.678, 2
600, 0.5947653429602888, 102.42, 4
700, 0.5866425992779783, 59.82, 2
800, 0.5971720818291215, 239.805, 6
900, 0.5821299638989169, 89.309, 2
1000, 0.5998796630565584, 121.354, 2

net.train(train, 0.5, 50, 0.05, 0.25);
1, 0.6013838748495788, 0.478, 3
2, 0.5719013237063778, 0.342, 2
3, 0.5827316486161251, 0.538, 2
5, 0.5980746089049338, 0.739, 2
10, 0.6302647412755716, 1.243, 2
20, 0.6077015643802648, 2.289, 2
30, 0.6335740072202166, 5.043, 3
40, 0.6263537906137184, 6.62, 3
50, 0.6311672683513839, 8.228, 3
60, 0.6329723225030084, 6.479, 2
70, 0.6251504211793021, 7.365, 2
80, 0.6435018050541517, 8.495, 2
90, 0.605595667870036, 9.509, 2
100, 0.6119133574007221, 10.635, 2
110, 0.6332731648616126, 17.506, 3
120, 0.6386883273164862, 12.851, 2
130, 0.631768953068592, 13.776, 2
140, 0.6260529482551144, 14.944, 2
150, 0.621841155234657, 22.125, 2
160, 0.6380866425992779, 20.516, 2
170, 0.6064981949458483, 18.902, 2
180, 0.6356799037304453, 20.036, 2
190, 0.6284596871239471, 23.931, 2
200, 0.644705174488568, 23.698, 2
210, 0.6266546329723225, 30.408, 2
220, 0.6242478941034898, 53.514, 3
230, 0.6519253910950662, 24.653, 2
240, 0.6335740072202166, 37.915, 2
250, 0.641395908543923, 27.681, 2
300, 0.6278580024067388, 33.238, 2
400, 0.6344765342960289, 43.034, 2
500, 0.6248495788206979, 53.246, 2
600, 0.6101083032490975, 64.013, 2
700, 0.6311672683513839, 76.452, 2
800, 0.6302647412755716, 95.726, 2
900, 0.6425992779783394, 100.968, 2
1000, 0.6380866425992779, 115.414, 2








Total proteins:111
Total aminos  :18105
Total proteins:17
Total aminos  :3520

Data set valid    :true
Feature length    :357

Training set valid:true
Training size     :14781

Tuning set valid  :true
Tuning size       :3324

Test set valid  :true
Test size       :3520



net.train(train, tune, 0.03, 100, 0.007, 0.75, 0.00005);
Loading time      :0.334s
1, 0.5747, 0.493, 4
2, 0.5844, 0.303, 2
3, 0.6099, 0.459, 3
5, 0.6151, 1.02, 4
10, 0.6153, 1.391, 3
20, 0.5969, 3.321, 4
30, 0.6213, 3.635, 3
40, 0.6202, 4.711, 3
50, 0.6145, 5.966, 3
60, 0.6199, 7.119, 3
70, 0.6185, 8.651, 3
80, 0.5974, 9.225, 3
90, 0.6108, 20.986, 6
100, 0.6236, 11.756, 3
110, 0.6153, 17.226, 4
120, 0.6230, 14.08, 3
130, 0.6051, 20.277, 4
140, 0.6000, 27.469, 5
150, 0.6088, 17.663, 3
160, 0.6131, 25.208, 4
170, 0.6114, 40.339, 6
180, 0.6153, 28.297, 4
190, 0.6040, 29.943, 4
200, 0.6190, 15.992, 2
210, 0.6179, 25.002, 3
220, 0.6193, 26.199, 3
230, 0.6173, 36.288, 4
240, 0.6082, 37.83, 4
250, 0.6068, 49.194, 5
300, 0.6207, 35.053, 3
400, 0.6048, 77.988, 5
500, 0.6054, 100.281, 5
600, 0.6125, 53.625, 2
700, 0.6105, 125.126, 4
800, 0.6122, 141.158, 4
900, 0.6170, 116.849, 3
1000, 0.6085, 184.415, 4

Total proteins:128
Total aminos  :21625

Hidden units: 7
Max epoch   : 1000
eta         : 0.05000000
epsilon     : 0.00800000
alpha       : 0.00000000
lambda      : 0.00000000

Accuracy    : 0.6244
Epoch       : 6
Elapsed time: 1.703






double eta = 0.01;

		int maxEpoch = 1000;

		double epsilon = 0.009;

		double alpha = 0.75;

		double lambda = 0.000008;



1,0.5800825593395251
4,0.6236842105263157
7,0.6238132094943241
10,0.6199948400412797
13,0.6239164086687307
16,0.6220588235294118
19,0.6235810113519091
22,0.6237358101135191
25,0.6219298245614034
28,0.6230392156862745
31,0.6219556243550052
34,0.6218266253869968
37,0.6224200206398349
40,0.6221620227038185
43,0.6255417956656346
46,0.6214138286893706
49,0.6239938080495356
52,0.6197626418988648
55,0.6234004127966977
58,0.6237100103199175
61,0.6214654282765737
64,0.621671826625387
67,0.6245872033023737
70,0.6210526315789474
73,0.6221362229102166
76,0.6245098039215686
79,0.6239422084623323
82,0.6218008255933952
85,0.6242776057791537
88,0.6233230134158927
91,0.6240454076367389
94,0.62218782249742
97,0.6239422084623322
100,0.6220588235294118








///////////


	private static void xorExamples(int epochs) {

		Instance[] m = new Instance[4];

		m[0] = new Instance();
		m[0].features = new double[] { 0, 0 };
		m[0].target = new double[] { 0 };

		m[1] = new Instance();
		m[1].features = new double[] { 0, 1 };
		m[1].target = new double[] { 1 };

		m[2] = new Instance();
		m[2].features = new double[] { 1, 0 };
		m[2].target = new double[] { 1 };

		m[3] = new Instance();
		m[3].features = new double[] { 1, 1 };
		m[3].target = new double[] { 0 };

		NeuralNet net = new NeuralNet();

		Function sigmoid = new Sigmoid();
		WeightInitializer weightInit = new DefaultWeightInitializer();

		net.addLayer(2)
				.activationFunction(sigmoid)
				.weightInitializer(weightInit);

		net.addLayer(5)
				.activationFunction(sigmoid)
				.weightInitializer(weightInit);

		net.addLayer(1)
				.activationFunction(sigmoid)
				.weightInitializer(weightInit);

		net.train(m, m, 0.5, 35000, 0.0000000005, 0.75, 0.0000);

		for (Instance t : m) {
			double[] out = net.predict(t.features);
			Trace.log("[", Format.matrix(t.features, 4), "]=[", Format.matrix(out, 4), "]");
		}
	}
	
	

public class Program {

	private static Instance[] makeExamples() {
		Instance[] examples = new Instance[4];
		Instance x;
		x = new Instance(3, 2);
		x.features[0] = 0.2;
		x.features[1] = 0.9;
		x.features[2] = 0.4;
		x.target[0] = 0.7;
		x.target[1] = 0.3;
		examples[0] = x;

		x = new Instance(3, 2);
		x.features[0] = 0.1;
		x.features[1] = 0.3;
		x.features[2] = 0.5;
		x.target[0] = 0.6;
		x.target[1] = 0.4;
		examples[1] = x;

		x = new Instance(3, 2);
		x.features[0] = 0.9;
		x.features[1] = 0.7;
		x.features[2] = 0.8;
		x.target[0] = 0.9;
		x.target[1] = 0.5;
		examples[2] = x;

		x = new Instance(3, 2);
		x.features[0] = 0.6;
		x.features[1] = 0.4;
		x.features[2] = 0.3;
		x.target[0] = 0.2;
		x.target[1] = 0.8;
		examples[3] = x;
		return examples;
	}


	private static Instance[] makeSimpleExamples() {
		Instance[] examples = new Instance[1];
		Instance x;
		x = new Instance();
		x.features = new double[] { 0.3, 0.7 };
		x.target = new double[] { 1 };
		examples[0] = x;
		return examples;
	}


	private static void stepByStepExamples() {
		NeuralNet net = new NeuralNet();

		Function sigmoid = new Sigmoid();
		WeightInitializer weightInit = new DefaultWeightInitializer();

		net.addLayer(2)
				.activationFunction(sigmoid)
				.weightInitializer(weightInit);

		net.addLayer(2)
				.activationFunction(sigmoid)
				.weightInitializer(weightInit);

		net.addLayer(2)
				.activationFunction(sigmoid)
				.weightInitializer(weightInit);

		double[][][] w = new double[3][][];
		w[0] = new double[2][2];
		w[1] = new double[2][3];
		w[2] = new double[2][3];

		w[1][0][0] = .35;
		w[1][0][1] = .15;
		w[1][0][2] = .20;

		w[1][1][0] = .35;
		w[1][1][1] = .25;
		w[1][1][2] = .30;

		w[2][0][0] = .60;
		w[2][0][1] = .40;
		w[2][0][2] = .45;

		w[2][1][0] = .60;
		w[2][1][1] = .50;
		w[2][1][2] = .55;

		Instance[] o = new Instance[1];
		o[0] = new Instance();
		o[0].features = new double[] { .05, .10 };
		o[0].target = new double[] { .01, .99 };

		net.weights(w);
		net.train(o, 0.5, 0, 0, 0.05, 100000);

		double[] f = new double[] { 0.05, 0.1 };
		double[] out = net.predict(f);
		Trace.log("[", Format.matrix(f), "]=[", Format.matrix(out), "]");
	}


	private static void sineExamples(int epochs) {
		double delta = Math.PI / 1000;
		double r = 0;
		List<Instance> m = new ArrayList<Instance>();

		while (r < (2 * Math.PI)) {
			Trace.log("sine(", r, ")=", Math.sin(r));
			r = r + delta;
			Instance x = new Instance();
			x.features = new double[] { r };
			x.target = new double[] { Math.sin(r) };
			m.add(x);
		}

		NeuralNet net = new NeuralNet();
		Function htan = new HyperbolicTangent();
		WeightInitializer weightInit = new DefaultWeightInitializer();
		Instance[] examples = m.toArray(new Instance[m.size()]);

		net.addLayer(1)
				.activationFunction(htan)
				.weightInitializer(weightInit);

		net.addLayer(100)
				.activationFunction(htan)
				.weightInitializer(weightInit);

		net.addLayer(100)
				.activationFunction(htan)
				.weightInitializer(weightInit);

		net.addLayer(100)
				.activationFunction(htan)
				.weightInitializer(weightInit);

		net.addLayer(1)
				.activationFunction(htan)
				.weightInitializer(weightInit);

		net.train(examples, examples, 0.0025, 500, 0.00005, 0.85, 0.00008);

		for (Instance t : m) {
			double[] out = net.predict(t.features);
			Trace.log("(", Format.matrix(t.target, 4), ",", Format.matrix(out, 4), ")");
		}

	}

	
	


